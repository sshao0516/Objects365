<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Objects365 Dataset">
    <meta name="author" content="Shuai Shao">

    <title>Detection In the Wild Challenge Workshop 2019</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/modern-business.css" rel="stylesheet">

  </head>

  <body>

    <header>

        <!-- Navigation -->
	    <script type="text/javascript" src="navigation.js"></script>

        <div class="narrow-carousel-item active" style="background-image: url('images/bg_1400x500.jpg')">
          <div class="narrow-carousel-caption d-none d-md-block">
            <h1>Detection In the Wild Challenge Workshop 2019</h1>
			<h4>17th June, 2019</h4>
			<h4>Long Beach, CA</h4>
            <h4>in conjunction with CVPR 2019</h4>
          </div>
        </div>
    </header>

    <!-- Page Content -->
    <div class="container">

      <!-- h1 class="my-4">Welcome to Modern Business</h1 -->
      <h1 class="my-4"></h1>

      <div class="row">
        <div class="col-lg-12">
          <p>
          Object detection is of significant value to the Computer Vision and Pattern Recognition communities as it is one of the fundamental vision problems. In this workshop, we will introduce two new benchmarks for the object detection task: <b>Objects365</b> and <b>CrowdHuman</b>, both of which are designed and collected in the wild. 
          Objects365 benchmark targets to address the large-scale detection with 365 object categories. There will be two tracks: full track with all of 365 object categories on the 600K training images and tiny track to address the 100 challenging categories on sub-set of the training images. CrowdHuman, on the other hand, is targeting the problem of human detection in the crowd. We hope these two datasets can provide the diverse and practical benchmarks to advance the research of object detection. Also, this workshop can serve as a platform to push the upper-bound of object detection research.
          </p>
          <p><font color="red">[News]</font> The workshop website is now online.</p>
        </div>

      </div>
      <!-- /.row -->

      <hr>
      <div class="row">
        <div class="col-lg-12">
          <h3>Important Dates</h3>
        </div>
        <div class='col-2'></div>
        <div class="col-lg-8 bg-light">
          <table class='table'>
            <tbody>
              <tr>
                <td>Challenge Launch Date</td>
                <td><del>April 16, 2019</del></td>
              </tr>
              <tr>
                <td>Testing Data Release</td>
                <td><del>May 10, 2019</del></td>
              </tr>
              <tr>
                <td>Result Submissions Deadline</td>
                <td><del>June 12, 2019</del></td>
              </tr>
              <!--tr>
                <td>Challenge Award Notification</td>
                <td>TBD</td>
              </tr-->
              <tr>
                <td>Workshop date</td>
                <td>June 17, 2019</td>
              </tr>
              <tr><td></td><td></td></tr>
            </tbody>
          </table>
          <p>
          </p>
        </div>

      </div>
      <!-- /.row -->

      <hr>
      <div class="row">
        <div class="col-lg-12">
          <h3>Schedule</h3>
          <h6>June 17, 2019</h6>
          <h6>Hyatt Regency E</h6>
	  <p>We invite the top three teams of each track to share the experience of the competition.</p>
        </div>
        <div class="col-lg-12 bg-light">
          <table class='table'>
            <tbody>
              <tr>
                <td>13:30-13:50</td>
                <td>Introduction for DIW2019</td>
                <td>Gang Yu, MEGVII</td>
              </tr>
              <tr>
                <td>13:50-14:10</td>
                <td>Outstanding team talk of Objects365 track. <a href="slides/object365_talk_bytedance.pdf">[slides]</a></td>
                <td>Hengkai Guo, Bytedance AI Lab</td>
              </tr>
              <tr>
                <td>14:10-14:30</td>
                <td>Invited talk: Feature Selective Anchor Free Module for Single Shot Object Detection. <a href="slides/fsaf-diw.pptx">[slides]</a></td>
                <td>Chenchen Zhu, CMU</td>
              </tr>
              <tr>
                <td>14:30-14:50</td>
                <td>Invited talk: Bounding Box Regression with Uncertainty for Accurate Object Detection. <a href="slides/KLLoss CVPR'19.pdf">[slides]</a></td>
                <td>Yihui He, CMU</td>
              </tr>
              <tr>
                <td>14:50-15:15</td>
                <td>Outstanding team talk of Objects365 track. <a href="slides/Obj365_BaiduVIS.pdf">[slides]</a></td>
                <td>Dongliang He, Baidu VIS</td>
              </tr>
              <tr>
                <td>15:15-16:00</td>
                <td>Coffee Break</td>
                <td></td>
              </tr>
              <tr>
                <td>16:00-16:40</td>
                <td>Invited talk: Deformation Modeling in Convnets. <a href="slides/STN_DCN_short.pdf">[slides]</a></td>
                <td>Jifeng Dai, MSRA</td>
              </tr>
              <tr>
                <td>16:40-17:05</td>
                <td>Outstanding team talk of CrowdHuman track. <a href="slides/crowdhuman present v2-Tencent AI Lab.pptx">[slides]</a></td>
                <td>Zequn Jie, Tencent AI Lab</td>
              </tr>
              <tr><td></td><td></td><td></td></tr>
            </tbody>
          </table>
          <p>
          </p>
        </div>

      </div>
      <!-- /.row -->

      <hr>
      <div class="row">
        <h3>Invited Speakers</h3>
        <div class="col-lg-12">
        </div>
        <div class="col-lg-2">
        <a href="#"><img class="card-img" src="images/zhuchenchen.jpeg" alt=""></a>
        </div>
        <div class="col-lg-8">
          <p><b>Chenchen Zhu</b> is a Ph.D. student from Department of Electrical & Computer Engineering (ECE) at Carnegie Mellon University (CMU). He works with Prof. Marios Savvides at the CyLab Biometrics Center. His research interest mainly lies in computer vision and deep learning, with applications on object detection in general and facial analysis.</p>
        </div>

        <div class="col-lg-12">
        </div>

        <div class="col-lg-2">
        <a href="#"><img class="card-img" src="images/heyihui.png" alt=""></a>
        </div>
        <div class="col-lg-8">
        <p>
        <b>Yihui He</b>, He is a CMU master student, with his interest focus on Computer Vision and Deep Learning. 
During he undergrad study he was fortunate to be an intern with Jian Sun (Megvii/Face++), Song Han (MIT) and Alan Yuille (JHU). He has a track record of contributing to CNN efficient inference. Particularly, he designed channel pruning to effectively prune channels. He further proposed AMC to sample the design space of channel pruning via reinforcement learning, which greatly improved the performance.
He served as a reviewer for ICCV'19, CVPR'19, ICLR'19, NIPS'18, TIP and IJCV.

        </p>
        </div>
        <div class="col-lg-12">
        </div>
        <div class="col-lg-2">
        <a href="http://www.jifengdai.org/"><img class="card-img" src="images/daijifeng_320x320.jpg" alt=""></a>
        </div>
        <div class="col-lg-8">
        <p>
        <b>Jifeng Dai</b>, Senior Researcher in the  Visual Computing Group of Microsoft Research Asia. He received the B.S. degree and the Ph.D. degree from Tsinghua University with honor in 2009 and 2014 respectively. He was also a visiting student in University of California, Los Angeles (UCLA) from 2012 to 2013. He is the author of R-FCN and Deformable ConvNets. His citation in google scholar has exceeded 4000. His team won the COCO competition championship in 2015 and 2016 and won a third place in 2017. And he served as the Senior PC Member of the AAAI 2018.
        </p>
        </div>

      </div>
      <!-- /.row -->

      <hr>
      <div class="row">
        <h3>Workshop Overview</h3>
        <div class="col-lg-12">
          The competitions platform is provided by <a href="https://www.biendata.com/">Biendata</a>. The entrances of registration and submission are about to open. Wait a moment.
          <h4>Objects365 Challenge Track</h4>
          <p>The <a href="https://www.objects365.org/">Objects365</a> is a brand new dataset, designed to spur object detection research with a focus on diverse objects in the Wild. Objects365 has 365 object classes annotated on 638K images, totally with more than 10 million bounding boxes in the training set. 
          Thus the annotations cover common objects occurring in all kinds of scene categories. 
          Challenge for Objects365 is proposed to have two tracks:
          </p>
          <ul>
            <li><b>Full Track.</b>
            The goal of Full Track is to explore the upper-bound performance of object detection systems, given all the 365 classes and 600K+ training images. 30K images are used for validation and another 100K images are used for testing. To evaluate the performance of object detection, the evaluation criteria for COCO (IOU from 0.5 to 0.95) benchmark will be adopted.
            </li>
            <li><b>Tiny Track.</b>
            Tiny Track is to lower the entry threshold, accelerate the algorithm iteration speed, and study the long tail category detection problem.From the Objects365 dataset, 65 categories are selected, and contestants can training model using 10K training data.
            </li>
          </ul>
          <h4>CrowdHuman Challenge Track</h4>
          <p>The <a href="http://www.crowdhuman.org/">CrowdHuman</a> dataset is large, rich-annotated and contains high diversity. It contains 15000, 4370 and 5000 images for training, validation, and testing, respectively. There are a total of 340K human instances and 22.6 persons per image from the train set, with various kinds of occlusions in the dataset. Each human instance is annotated with a head bounding-box, human visible-region bounding-box and human full-body bounding-box. 
          We believe this dataset will serve as a solid baseline and help promote future research in human detection tasks, especially in the crowded environment. 
          </p>
        </div>

      </div>
      <!-- /.row -->

      <hr>
      <div class="row">
        <h3>Organizers</h3>
        <div class="col-12"></div>
        <p>Contact us at <a href="mailto:info@objects365.com">info@objects365.org</a>.</p>
        <div class="col-12"></div>

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.skicyyu.org/"><img class="card-img" src="images/yugang_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.skicyyu.org/">Gang Yu</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Gang Yu -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="https://www.sshao.com/"><img class="card-img" src="images/shaoshuai_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://www.sshao.com/">Shuai Shao</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Shuai Shao -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://jiansun.org/"><img class="card-img" src="images/sunjian_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://jiansun.org/">Jian Sun</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Jian Sun -->
      </div>

      <div class="row">
        <h3>Committee</h3>
        <div class="col-12"></div>
        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ"><img class="card-img" src="images/zhangxiangyu.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ">Xiangyu Zhang</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Xiangyu Zhang -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.zemingli.com/"><img class="card-img" src="images/lzm.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.zemingli.com/">Zeming Li</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Zeming Li -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="https://yichenwei.github.io/"><img class="card-img" src="images/weiyichen_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://yichenwei.github.io/">Yichen Wei</a>
              </h4>
              <p class="card-text">Megvii Technology</p>
            </div>
          </div>
        </div> <!-- Yichen Wei -->

        <div class="col-12"></div>
        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.jifengdai.org/"><img class="card-img" src="images/daijifeng_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.jifengdai.org/">Jifeng Dai</a>
              </h4>
              <p class="card-text">Microsoft</p>
            </div>
          </div>
        </div> <!-- Jifeng Dai -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.shaoqingren.com/"><img class="card-img" src="images/renshaoqing_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.shaoqingren.com/">Shaoqing Ren</a>
              </h4>
              <p class="card-text">Momenta.ai</p>
            </div>
          </div>
        </div> <!-- Shaoqing Ren -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="https://cse.buffalo.edu/~jsyuan/"><img class="card-img" src="images/yuanjunsong_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://cse.buffalo.edu/~jsyuan/">Junsong Yuan</a>
              </h4>
              <p class="card-text">SUNY at Buffalo</p>
            </div>
          </div>
        </div> <!-- Junsong Yuan -->

        <div class="col-12"></div>
        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.ganghua.org/"><img class="card-img" src="images/huagang_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.ganghua.org/">Gang Hua</a>
              </h4>
              <p class="card-text">Wormpex AI Research</p>
            </div>
          </div>
        </div> <!-- Gang Hua -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://keg.cs.tsinghua.edu.cn/jietang/"><img class="card-img" src="images/tangjie_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://keg.cs.tsinghua.edu.cn/jietang/">Jie Tang</a>
              </h4>
              <p class="card-text">Tsinghua University</p>
            </div>
          </div>
        </div> <!-- Jie Tang -->

        <div class="col-lg-4 col-sm-12 portfolio-item">
          <div class="people">
            <div class="card-img-left">
              <a href="http://www.idm.pku.edu.cn/~tjhuang/index-en.html"><img class="card-img" src="images/huangtiejun_320x320.jpg" alt=""></a>
            </div>
            <div class="card-body">
              <h4 class="card-title">
                <a href="http://www.idm.pku.edu.cn/~tjhuang/index-en.html">Tiejun Huang</a>
              </h4>
              <p class="card-text">Peking University</p>
            </div>
          </div>
        </div> <!-- Jiejun Huang -->

      </div>
      <!-- /.row -->
      <hr>

      <div class="row">
        <h3>Sponsors</h3>
        <div class="col-12"></div>
        <div class="col-lg-4 col-sm-12">
          <img src="images/logo.png" width=100% alt="Megvii Technology">
        </div>
        <div class="col-lg-4 col-sm-12">
          <img src="images/BAAI_logo.jpg" width=100% alt="Beijing Academy of Artificial Intelligence">
        </div>

      </div>
      <!-- /.row -->
      <hr>

    </div>
    <!-- /.container -->

    <!-- Footer -->
    <footer class="py-5 bg-dark">
	  <script type="text/javascript" src="footer.js"></script>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  </body>

</html>
